{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Spotipy\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials, SpotifyOAuth\n",
    "\n",
    "# Etc\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load API KEYS from `.env` file\n",
    "It should have the following format:\n",
    "```\n",
    "OPENAI_API_KEY=tx-GMdXEVIK0GmCudMGHpEqS3DqduEKhMzcEXwpuxt8JyEkRUZ0P\n",
    "SPOTIPY_CLIENT_ID=gt824gbg80dg5d88b84ed36f09ef8ff6\n",
    "SPOTIPY_CLIENT_SECRET=e8e8742257e830318e443zc23z320320\n",
    "SPOTIPY_REDIRECT_URI=http://localhost:8080\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:05:30.716426045Z",
     "start_time": "2024-03-06T20:05:30.701485669Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Verbose request logging, optional (for troubleshooting API errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T18:08:52.520591488Z",
     "start_time": "2024-03-06T18:08:52.325930266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# The `requests` library logs using the `urllib3` logger.\n",
    "# logger = logging.getLogger('urllib3')\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "\n",
    "class LoggingSession(requests.Session):\n",
    "    def send(self, request, **kwargs):\n",
    "        # Convert request to cURL command and log it\n",
    "        curl_cmd = self.request_to_curl(request)\n",
    "        logging.debug(\"cURL command: \\n%s\\n\", curl_cmd)\n",
    "\n",
    "        # Proceed with sending the request\n",
    "        return super().send(request, **kwargs)\n",
    "\n",
    "    def request_to_curl(self, prepared_request):\n",
    "        parts = [\"curl\", \"-X\", prepared_request.method]\n",
    "    \n",
    "        # Add the full URL, properly quoted to handle special characters\n",
    "        parts.append(f\"'{prepared_request.url}'\")\n",
    "    \n",
    "        # Add headers, each header properly quoted\n",
    "        for key, value in prepared_request.headers.items():\n",
    "            parts.append(f\"-H '{key}: {value}'\")\n",
    "    \n",
    "        # For GET requests, data is not typically included, but we'll add this for completeness for POST/PUT requests\n",
    "        if prepared_request.body:\n",
    "            # Assuming the body is a string, it needs to be properly escaped to be a valid shell argument\n",
    "            # shlex.quote can be used for this purpose in an actual implementation, but here we'll manually quote for clarity\n",
    "            body = prepared_request.body.decode('utf-8') if isinstance(prepared_request.body, bytes) else prepared_request.body\n",
    "            parts.append(f\"--data-raw '{body}'\")\n",
    "    \n",
    "        curl_cmd = \" \".join(parts)\n",
    "        return curl_cmd\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize the custom logging session\n",
    "logging_session = LoggingSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create and authenticate the Spotify API client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:05:36.061656676Z",
     "start_time": "2024-03-06T20:05:36.008850154Z"
    }
   },
   "outputs": [],
   "source": [
    "auth = SpotifyClientCredentials(\n",
    "    client_id=os.environ['SPOTIPY_CLIENT_ID'],\n",
    "    client_secret=os.environ['SPOTIPY_CLIENT_SECRET']\n",
    ")\n",
    "scope = ','.join([\n",
    "    \"user-library-read\",\n",
    "    \"playlist-read-private\",\n",
    "    \"playlist-modify-private\"\n",
    "])\n",
    "\n",
    "try:\n",
    "    requests_session = logging_session\n",
    "except:\n",
    "    requests_session = True\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope), requests_session=requests_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Spotify info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:06:03.843565660Z",
     "start_time": "2024-03-06T20:06:02.352126190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your user ID\n",
    "USER_ID = '1251572084'\n",
    "\n",
    "# The playlist you are scraping\n",
    "PLAYLIST_ID = '34rMzK9lmMfpgM2Gzx0T1d'\n",
    "PLAYLIST_PREFIX = sp.playlist(PLAYLIST_ID)['name']\n",
    "\n",
    "# Number of categories to create\n",
    "NUM_CATEGORIES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Get the tracks from a playlist, create a DataFrame, and save it to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:04.988076838Z",
     "start_time": "2024-03-06T20:10:58.823856973Z"
    }
   },
   "outputs": [],
   "source": [
    "if Path(f'playlist-{PLAYLIST_ID}.pkl').exists():\n",
    "    df = pd.read_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "items = []\n",
    "offset = 0\n",
    "page = 100\n",
    "\n",
    "results = sp.playlist_tracks(playlist_id=PLAYLIST_ID)\n",
    "total = results['total']\n",
    "\n",
    "for i in tqdm(range(0, total)):\n",
    "    if i != 0 and i % page == 0:\n",
    "        offset += page\n",
    "        results = sp.playlist_tracks(playlist_id=PLAYLIST_ID, offset=offset)\n",
    "    \n",
    "    item = results['items'][i % page]\n",
    "    track = item['track']\n",
    "\n",
    "    if track['id'] in df.index:\n",
    "        continue\n",
    "    \n",
    "    d = {'id': track['id'], \n",
    "         'uri': track['uri'],\n",
    "         'popularity': track['popularity'],\n",
    "         'album': track['album']['name'],\n",
    "         'artists': [artist['name'] for artist in track['artists']],\n",
    "         'artists_id': [artist['id'] for artist in track['artists']],\n",
    "         'name': track['name'],\n",
    "         'release_date': track['album']['release_date']}\n",
    "    items.append(d)\n",
    "\n",
    "if len(items) > 0:\n",
    "    print(f'Adding {len(items)} new tracks')\n",
    "    df_new_tracks = pd.DataFrame(items)\n",
    "    df_new_tracks.set_index('id', inplace=True)\n",
    "    df = pd.concat([df, df_new_tracks])\n",
    "    \n",
    "    df.to_csv(f'playlist-{PLAYLIST_ID}.csv')\n",
    "    df.to_excel(f'playlist-{PLAYLIST_ID}.xlsx', engine='openpyxl')\n",
    "    df.to_json(f'playlist-{PLAYLIST_ID}.json', orient='index')\n",
    "    df.to_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "else:\n",
    "    print('No new tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Get genre information for each artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:11:14.292861327Z",
     "start_time": "2024-03-06T20:11:14.107543037Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "all_artists = df['artists_id'].explode().unique().tolist()\n",
    "\n",
    "if Path('artists.pkl').exists():\n",
    "    df_artists = pd.read_pickle(f'artists.pkl')\n",
    "    existing_artists = set(df_artists.index)\n",
    "    all_artists = [artist for artist in all_artists if artist not in existing_artists]\n",
    "else:\n",
    "    df_artists = pd.DataFrame()\n",
    "\n",
    "total = len(all_artists)\n",
    "\n",
    "items = []\n",
    "offset = 0\n",
    "page = 50\n",
    "\n",
    "for i in tqdm(range(0, total)):\n",
    "    if i % page == 0:\n",
    "        try:\n",
    "            results = sp.artists(all_artists[offset:offset+page])\n",
    "        except Exception as e:\n",
    "            # print(f'Error: {e}')\n",
    "            break\n",
    "        offset += page\n",
    "\n",
    "    artist = results['artists'][i % page]\n",
    "    d = {'id': artist['id'], 'genres': artist['genres'], 'popularity': artist['popularity']}\n",
    "    items.append(d)\n",
    "\n",
    "if len(items) > 0:\n",
    "    print(f'Adding {len(items)} new artists')\n",
    "    df_new_artists = pd.DataFrame(items)\n",
    "    df_new_artists.set_index('id', inplace=True)\n",
    "    df_artists = pd.concat([df_artists, df_new_artists])\n",
    "    \n",
    "    df_artists.to_csv(f'artists.csv')\n",
    "    df_artists.to_excel(f'artists.xlsx', engine='openpyxl')\n",
    "    df_artists.to_json(f'artists.json', orient='index')\n",
    "    df_artists.to_pickle(f'artists.pkl')\n",
    "else:\n",
    "    print('No new artists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Add genre information to tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:29:54.270738815Z",
     "start_time": "2024-03-06T20:29:54.070979972Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "df_artists = pd.read_pickle(f'artists.pkl')\n",
    "\n",
    "items = []\n",
    "\n",
    "for i, x in tqdm(df.iterrows(), total=len(df)):\n",
    "    if 'genres' in x and pd.notna(x['genres']):\n",
    "        continue\n",
    "    \n",
    "    genres = set()\n",
    "    for artist_id in x['artists_id']:\n",
    "        artist = df_artists.loc[artist_id]\n",
    "        for genre in artist['genres']:\n",
    "            if genre not in genres:\n",
    "                genres.add(genre)\n",
    "    items.append({'id': i, 'genres': tuple(genres)})\n",
    "\n",
    "\n",
    "if len(items) > 0:\n",
    "    df_genres = pd.DataFrame(items)\n",
    "    df_genres.set_index('id', inplace=True)\n",
    "    df = pd.concat([df, df_genres], axis=1)\n",
    "    \n",
    "    df.to_csv(f'playlist-{PLAYLIST_ID}.csv')\n",
    "    df.to_excel(f'playlist-{PLAYLIST_ID}.xlsx', engine='openpyxl')\n",
    "    df.to_json(f'playlist-{PLAYLIST_ID}.json', orient='index')\n",
    "    df.to_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "    print(f'Added genre information to {len(items)} tracks')\n",
    "else:\n",
    "    print('No genre information added.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Get audio features for tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:32:04.161113960Z",
     "start_time": "2024-03-06T20:32:04.097436008Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "track_ids = df.index.tolist()\n",
    "if 'acousticness' in df.columns:\n",
    "    track_ids_with_audio_features = set(df[df['acousticness'].notna()].index)\n",
    "    track_ids = [track_id for track_id in track_ids if track_id not in track_ids_with_audio_features]\n",
    "\n",
    "total = len(track_ids)\n",
    "offset = 0\n",
    "page = 100\n",
    "\n",
    "seen = 0\n",
    "for i in tqdm(range(0, total)):\n",
    "    seen = i\n",
    "    if i % page == 0:\n",
    "        try:\n",
    "            results = sp.audio_features(track_ids[offset:offset+page])\n",
    "        except Exception as e:\n",
    "            # print(f'Error: {e}')\n",
    "            break\n",
    "        offset += page\n",
    "    \n",
    "    audio_features = results[i % page]\n",
    "    for feature in ['acousticness', \n",
    "                    'danceability', \n",
    "                    'duration_ms', \n",
    "                    'energy', \n",
    "                    'instrumentalness', \n",
    "                    'key', \n",
    "                    'liveness', \n",
    "                    'loudness', \n",
    "                    'mode', \n",
    "                    'speechiness', \n",
    "                    'tempo', \n",
    "                    'time_signature', \n",
    "                    'valence']:\n",
    "        df.loc[audio_features['id'], feature] = audio_features[feature]\n",
    "\n",
    "if seen > 0:\n",
    "    print(f'Adding {i} new audio features')\n",
    "    df.to_csv(f'playlist-{PLAYLIST_ID}.csv')\n",
    "    df.to_excel(f'playlist-{PLAYLIST_ID}.xlsx', engine='openpyxl')\n",
    "    df.to_json(f'playlist-{PLAYLIST_ID}.json', orient='index')\n",
    "    df.to_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "else:\n",
    "    print('No new audio features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create shuffled list of genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:32:09.064551585Z",
     "start_time": "2024-03-06T20:32:08.990800611Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "genres_list = (df[df['genres'].apply(lambda x: len(x) > 0)]['genres']).apply(lambda x: \", \".join(x)).tolist()\n",
    "random.seed(0)\n",
    "random.shuffle(genres_list)\n",
    "genres_text = \"\\n\".join(genres_list)\n",
    "with open(f'genres_text-{PLAYLIST_ID}.txt', 'w') as fp:\n",
    "    fp.write(genres_text)\n",
    "print(genres_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create categories prompt for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:40:23.037585400Z",
     "start_time": "2024-03-06T20:40:23.005832306Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=0)\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"I have a list of songs, each with one or more genres associated with it. Based on these genres, I would like you to analyze the list and create {num_categories} distinct categories that these songs could be grouped into. Each category should represent a unique theme or commonality found within the genres. Please provide a brief description for each category to explain the common theme or elements that define it.\\nPlease output each category using the following format:\\n[[NUMBER]]. **[[TITLE]]**: [[DESCRIPTION]]\\n\\nHere is the list of songs and their associated genres:\\n\\n{genres_text}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Test categories prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:40:23.980775810Z",
     "start_time": "2024-03-06T20:40:23.971255279Z"
    }
   },
   "outputs": [],
   "source": [
    "genres_text = open(f'genres_text-{PLAYLIST_ID}.txt', 'r').read()\n",
    "print(prompt.format(num_categories=NUM_CATEGORIES, genres_text=genres_text[:500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Prompt LLM for list of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:40:42.054696496Z",
     "start_time": "2024-03-06T20:40:25.696495530Z"
    }
   },
   "outputs": [],
   "source": [
    "genres_text = open(f'genres_text-{PLAYLIST_ID}.txt', 'r').read()\n",
    "\n",
    "if Path(f'category_output-{PLAYLIST_ID}.txt').exists():\n",
    "    categories_output = open(f'category_output-{PLAYLIST_ID}.txt', 'r').read()\n",
    "else:\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "    categories_output = chain.run(num_categories=NUM_CATEGORIES, genres_text=genres_text)\n",
    "    with open(f'category_output-{PLAYLIST_ID}.txt', 'w') as fp:\n",
    "        fp.write(categories_output)\n",
    "print(categories_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Parse category output from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:41:17.149996323Z",
     "start_time": "2024-03-06T20:41:17.108935252Z"
    }
   },
   "outputs": [],
   "source": [
    "categories_output = open(f'category_output-{PLAYLIST_ID}.txt', 'r').read()\n",
    "\n",
    "# Updated regex pattern to ensure entire descriptions are captured\n",
    "pattern = r\"(\\d+)\\.\\s*([^:]+):\\s*((?:.(?!\\n\\s*\\d+\\.))+.)\"\n",
    "\n",
    "matches = re.findall(pattern, categories_output, re.DOTALL)\n",
    "\n",
    "categories = {int(num): (name.strip(), desc.strip()) for num, name, desc in matches}\n",
    "\n",
    "data = [{'category_number': category_number,\n",
    "         'category_name': category_name,\n",
    "         'description': description\n",
    "         } for category_number, (category_name, description) in categories.items()]\n",
    "\n",
    "df_categories = pd.DataFrame(data)\n",
    "df_categories.to_csv(f'categories-{PLAYLIST_ID}.csv')\n",
    "df_categories.to_excel(f'categories-{PLAYLIST_ID}.xlsx', engine='openpyxl')\n",
    "df_categories.to_json(f'categories-{PLAYLIST_ID}.json', orient='index')\n",
    "df_categories.to_pickle(f'categories-{PLAYLIST_ID}.pkl')\n",
    "\n",
    "for category_number, (category_name, description) in categories.items():\n",
    "    print(f\"{category_number}. {category_name}: {description}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create categorization prompt for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:41:46.157683617Z",
     "start_time": "2024-03-06T20:41:46.055406691Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given a list of categories and their descriptions, please determine which category the following song fits best into. Use the song's genres, along with any other relevant information provided, to make your decision. After making your decision, structure your response as follows: Start with \"Category number:\" followed by the number of the category. Then, on a new line, write \"Category name:\" followed by the name of the category. Then, on a new line, write \"Reasoning:\" followed by a brief explanation of why the song fits best in the chosen category. Here are the categories:\n",
    "\n",
    "{categories_output}\n",
    "\n",
    "Song Information:\n",
    "\n",
    "    Name: {name}\n",
    "    Artists: {artists}\n",
    "    Album: {album}\n",
    "    Release Date: {release_date}\n",
    "    Genres: {genres}\n",
    "    Popularity: {popularity}\n",
    "    Danceability: {danceability}\n",
    "    Energy: {energy}\n",
    "    Key: {key}\n",
    "    Loudness: {loudness}\n",
    "    Mode: {mode}\n",
    "    Speechiness: {speechiness}\n",
    "    Acousticness: {acousticness}\n",
    "    Instrumentalness: {instrumentalness}\n",
    "    Liveness: {liveness}\n",
    "    Valence: {valence}\n",
    "    Tempo: {tempo}\n",
    "    Duration MS: {duration_ms}\n",
    "    Time Signature: {time_signature}\n",
    "\n",
    "Based on the genres listed and any other information you deem relevant from the song information provided, which of the categories does \"{name}\" by {artists} fit best into? Please explain your reasoning.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Test categorization prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:41:48.306206734Z",
     "start_time": "2024-03-06T20:41:48.196868883Z"
    }
   },
   "outputs": [],
   "source": [
    "categories_output = open(f'category_output-{PLAYLIST_ID}.txt', 'r').read()\n",
    "df = pd.read_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "track = df.iloc[0]\n",
    "\n",
    "print(prompt.format(categories_output=categories_output,\n",
    "                    name=track['name'],\n",
    "                    artists=\", \".join(track['artists']),\n",
    "                    album=track['album'],\n",
    "                    release_date=track['release_date'],\n",
    "                    genres=track['genres'],\n",
    "                    popularity=track['popularity'],\n",
    "                    danceability=track['danceability'],\n",
    "                    energy=track['energy'],\n",
    "                    key=track['key'],\n",
    "                    loudness=track['loudness'],\n",
    "                    mode=track['mode'],\n",
    "                    speechiness=track['speechiness'],\n",
    "                    acousticness=track['acousticness'],\n",
    "                    instrumentalness=track['instrumentalness'],\n",
    "                    liveness=track['liveness'],\n",
    "                    valence=track['valence'],\n",
    "                    tempo=track['tempo'],\n",
    "                    duration_ms=track['duration_ms'],\n",
    "                    time_signature=track['time_signature']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Test LLM categorization on single track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:42:08.285913511Z",
     "start_time": "2024-03-06T20:41:52.203690605Z"
    }
   },
   "outputs": [],
   "source": [
    "categories_output = open(f'category_output-{PLAYLIST_ID}.txt', 'r').read()\n",
    "df = pd.read_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "track = df.iloc[0]\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "# tracks = get_tracks(n=250, shuffle=True)\n",
    "# tracks = format_tracks(tracks)\n",
    "output = chain.run(categories_output=categories_output,\n",
    "                   name=track['name'],\n",
    "                   artists=\", \".join(track['artists']),\n",
    "                   album=track['album'],\n",
    "                   release_date=track['release_date'],\n",
    "                   genres=track['genres'],\n",
    "                   popularity=track['popularity'],\n",
    "                   danceability=track['danceability'],\n",
    "                   energy=track['energy'],\n",
    "                   key=track['key'],\n",
    "                   loudness=track['loudness'],\n",
    "                   mode=track['mode'],\n",
    "                   speechiness=track['speechiness'],\n",
    "                   acousticness=track['acousticness'],\n",
    "                   instrumentalness=track['instrumentalness'],\n",
    "                   liveness=track['liveness'],\n",
    "                   valence=track['valence'],\n",
    "                   tempo=track['tempo'],\n",
    "                   duration_ms=track['duration_ms'],\n",
    "                   time_signature=track['time_signature'])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Test track categorization output parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T20:42:10.287609934Z",
     "start_time": "2024-03-06T20:42:10.238443109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Regular expression pattern to match and extract the required fields\n",
    "pattern = r\"Category number: (\\d+)\\s+Category name: ([\\w\\s]+)\\s+Reasoning: (.+)\"\n",
    "\n",
    "# Search for the pattern in the LLM output\n",
    "match = re.search(pattern, output, re.DOTALL)\n",
    "\n",
    "if match:\n",
    "    # Extract the category number, name, and reasoning from the match\n",
    "    category_number = int(match.group(1))\n",
    "    category_name = match.group(2).strip()\n",
    "    reasoning = match.group(3).strip()\n",
    "\n",
    "    print(f\"Category Number: {category_number}\")\n",
    "    print(f\"Category Name: {category_name}\")\n",
    "    print(f\"Reasoning: {reasoning}\")\n",
    "else:\n",
    "    print(\"Required fields not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### For each track, prompt LLM to categorize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "categories_output = open(f'category_output-{PLAYLIST_ID}.txt', 'r').read()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, verbose=False)\n",
    "for i, track in tqdm(df.iterrows(), total=len(df)):\n",
    "    if 'category_number' in df.columns and pd.notna(df.loc[i, 'category_number']):\n",
    "        continue\n",
    "    \n",
    "    match = None\n",
    "    while not match:\n",
    "        output = chain.run(categories_output=categories_output,\n",
    "                           name=track['name'],\n",
    "                           artists=\", \".join(track['artists']),\n",
    "                           album=track['album'],\n",
    "                           release_date=track['release_date'],\n",
    "                           genres=track['genres'],\n",
    "                           popularity=track['popularity'],\n",
    "                           danceability=track['danceability'],\n",
    "                           energy=track['energy'],\n",
    "                           key=track['key'],\n",
    "                           loudness=track['loudness'],\n",
    "                           mode=track['mode'],\n",
    "                           speechiness=track['speechiness'],\n",
    "                           acousticness=track['acousticness'],\n",
    "                           instrumentalness=track['instrumentalness'],\n",
    "                           liveness=track['liveness'],\n",
    "                           valence=track['valence'],\n",
    "                           tempo=track['tempo'],\n",
    "                           duration_ms=track['duration_ms'],\n",
    "                           time_signature=track['time_signature'])\n",
    "        match = re.search(pattern, output, re.DOTALL)\n",
    "    if match:\n",
    "        category_number = int(match.group(1))\n",
    "        category_name = match.group(2).strip()\n",
    "        reasoning = match.group(3).strip()\n",
    "        df.at[i, 'category_number'] = category_number\n",
    "        df.at[i, 'category_name'] = category_name\n",
    "        df.at[i, 'reasoning'] = reasoning\n",
    "        \n",
    "        print(f\"Category: {category_number} ({category_name}), Name: {track['name']}, Artists: {', '.join(track['artists'])}\\nReasoning: {reasoning}\")\n",
    "    else:\n",
    "        print(\"Required fields not found.\")\n",
    "        break\n",
    "    \n",
    "    df.to_csv(f'playlist-{PLAYLIST_ID}.csv')\n",
    "    df.to_excel(f'playlist-{PLAYLIST_ID}.xlsx', engine='openpyxl')\n",
    "    df.to_json(f'playlist-{PLAYLIST_ID}.json', orient='index')\n",
    "    df.to_pickle(f'playlist-{PLAYLIST_ID}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "df_categories = pd.read_pickle(f'categories-{PLAYLIST_ID}.pkl')\n",
    "\n",
    "for category_number, category_name, description in df_categories.itertuples(index=False):\n",
    "    print(f\"Category: {category_number} ({category_name})\\nDescription: {description}\\n\")\n",
    "    tracks_to_add = []\n",
    "    tracks_in_category = df[df['category_number'] == category_number]\n",
    "    for i, x in tracks_in_category.iterrows():\n",
    "        print(f'{x[\"name\"]} by {\", \".join(x[\"artists\"])}')\n",
    "        tracks_to_add.append(x['uri'])\n",
    "    print('\\n')\n",
    "    \n",
    "    timestamp = datetime.now().isoformat()[:16].replace(':', '')\n",
    "    playlist_name = f\"{PLAYLIST_PREFIX} - {category_name.replace('*', '')}_{timestamp}\"\n",
    "    playlist_desc = re.sub(r'\\n+', ' ', description)[:512]\n",
    "    result = sp.user_playlist_create(user=USER_ID, \n",
    "                                     name=playlist_name, \n",
    "                                     public=False, \n",
    "                                     description=playlist_desc)\n",
    "    created_playlist_id = result['id']\n",
    "\n",
    "    offset = 0\n",
    "    while offset < len(tracks_to_add):\n",
    "        sp.playlist_add_items(playlist_id=created_playlist_id, \n",
    "                              items=tracks_to_add[offset:offset+100])\n",
    "        offset += 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Alternative code to update playlists during categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T21:17:11.306378339Z",
     "start_time": "2024-03-06T21:17:10.195320444Z"
    }
   },
   "outputs": [],
   "source": [
    "df_categories = pd.read_pickle(f'categories-{PLAYLIST_ID}.pkl')\n",
    "\n",
    "category_playlist_ids = {}\n",
    "print('Creating playlists')\n",
    "for category_number, category_name, description in df_categories.itertuples(index=False):\n",
    "    timestamp = datetime.now().isoformat()[:16].replace(':', '')\n",
    "    playlist_name = f\"{PLAYLIST_PREFIX} - {category_name.replace('*', '')}_{timestamp}\"\n",
    "    playlist_desc = re.sub(r'\\n+', ' ', description)[:512]\n",
    "    result = sp.user_playlist_create(user=USER_ID,\n",
    "                                     name=playlist_name,\n",
    "                                     public=False,\n",
    "                                     description=playlist_desc)\n",
    "    created_playlist_id = result['id']\n",
    "    category_playlist_ids[category_number] = created_playlist_id\n",
    "    \n",
    "    print(f'{created_playlist_id}: \"{playlist_name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T21:17:21.309832343Z",
     "start_time": "2024-03-06T21:17:20.762884266Z"
    }
   },
   "outputs": [],
   "source": [
    "category_playlist_track_ids = set([])\n",
    "for playlist_id in category_playlist_ids.values():\n",
    "    results = sp.playlist_tracks(playlist_id)\n",
    "    category_playlist_track_ids.update([item['track']['id'] for item in results['items']])\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        category_playlist_track_ids.update([item['track']['id'] for item in results['items']])\n",
    "print(f'Found {len(category_playlist_track_ids)} tracks in category playlists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-06T21:21:24.083020142Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'playlist-{PLAYLIST_ID}.pkl')\n",
    "categories_output = open(f'category_output-{PLAYLIST_ID}.txt', 'r').read()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, verbose=False)\n",
    "for i, track in tqdm(df.iterrows(), total=len(df)):\n",
    "    if i in category_playlist_track_ids:\n",
    "        continue\n",
    "    \n",
    "    if not 'category_number' in df.columns or pd.isna(df.loc[i, 'category_number']):\n",
    "        match = None\n",
    "        while not match:\n",
    "            output = chain.run(categories_output=categories_output,\n",
    "                               name=track['name'],\n",
    "                               artists=\", \".join(track['artists']),\n",
    "                               album=track['album'],\n",
    "                               release_date=track['release_date'],\n",
    "                               genres=track['genres'],\n",
    "                               popularity=track['popularity'],\n",
    "                               danceability=track['danceability'],\n",
    "                               energy=track['energy'],\n",
    "                               key=track['key'],\n",
    "                               loudness=track['loudness'],\n",
    "                               mode=track['mode'],\n",
    "                               speechiness=track['speechiness'],\n",
    "                               acousticness=track['acousticness'],\n",
    "                               instrumentalness=track['instrumentalness'],\n",
    "                               liveness=track['liveness'],\n",
    "                               valence=track['valence'],\n",
    "                               tempo=track['tempo'],\n",
    "                               duration_ms=track['duration_ms'],\n",
    "                               time_signature=track['time_signature'])\n",
    "            match = re.search(pattern, output, re.DOTALL)\n",
    "        if match:\n",
    "            category_number = int(match.group(1))\n",
    "            category_name = match.group(2).strip()\n",
    "            reasoning = match.group(3).strip()\n",
    "            df.at[i, 'category_number'] = category_number\n",
    "            df.at[i, 'category_name'] = category_name\n",
    "            df.at[i, 'reasoning'] = reasoning\n",
    "    \n",
    "            print(f\"Category: {category_number} ({category_name}), Name: {track['name']}, Artists: {', '.join(track['artists'])}\\nReasoning: {reasoning}\")\n",
    "        else:\n",
    "            print(\"Required fields not found.\")\n",
    "            break\n",
    "\n",
    "    category_number = df.at[i, 'category_number']\n",
    "    sp.playlist_add_items(category_playlist_ids[category_number], [track['uri']])\n",
    "\n",
    "    df.to_csv(f'playlist-{PLAYLIST_ID}.csv')\n",
    "    df.to_excel(f'playlist-{PLAYLIST_ID}.xlsx', engine='openpyxl')\n",
    "    df.to_json(f'playlist-{PLAYLIST_ID}.json', orient='index')\n",
    "    df.to_pickle(f'playlist-{PLAYLIST_ID}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
